---
title: 1. 한눈에 보는 머신러닝
author: Monch
category: Hands On Machine Learning 
layout: post
---

 <h2><b>용어</b></h2>

-  <b>머신러닝</b>
   - 일반적인 정의 : 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구분야(Arthur Samuel,1959)
   - 공학적인 정의 : 어떤 작업 T(Task)에 대한 컴퓨터의 프로그램의 성능을 P(Performance)로 측정했을 때 경험 E(Experiance)로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다. 
     Task : 목표라고 생각하면 된다. 내가 이미지를 분류할지, 단어의 문맥을 파악할지.
     Performance : 정답 label에 대한 정확도로 생각하면 된다. 물론 측정하는 방식에 따라 대상이 정답 label과 완전 똑같지 않을 수 있다.
     Experiance : 머신러닝의 학습은 input data, output data, loss, backpropagation으로 이루어진다. 어떠한 정보를 받아서 이러한 대답을 냈지만 오차가 어느정도 생겼기 때문에 이를 조정해야겠다. 이러한 과정을 경험이라고 정의한 것 같다.
-  <b>데이터 마이닝</b>
   - 머신러닝 기술을 적용해서 대용량의 데이터를 분석하면 겉으로는 보이지 않는 패턴을 파악하는 것
-  <b>분류 (classification)</b>
   - O,X를 맞추는 문제라고 생각하면 될 것 같다. 내가 고양이 데이터를 줬을 때 고양이 인가요? 아닌가요? 하는 Task의 종류이다. 
-  <b>회귀 (regression)</b>
   - 예측의 문제이다. 내가 고양이 데이터를 줬을 때 고양이가 맞을 확률 또는 아닐 확률에 대해 질문 하는 종류이다. 혹은 집의 가격 예측에도 쓸 수 있다.





 <h2><b>머신러닝은 어디에 뛰어난가</b></h2>

책에서는 다음과 같이 4가지를 소개한다.

- 기존의 방식보다 많은 규칙 또는 수작업이 필요한 문제
- 전통적인 방식으로는 해결 방법이 없는 복잡한 문제
- 유동적인 환경 문제
- 복잡한 문제와 대량의 데이터

그렇다면 머신러닝의 효과를 최대화로 올리는 것이 우리의 목적이 되는데 어떻게 하면 가능할까?

중요한 포인트가 여기에 명시되어 있다고 생각한다.

이 4가지는 하나의 공통점을 찾을 수 있다. 바로 우리가 파악하지 못하는 데이터의 규칙이 존재하는 데 이를 알기 어려울 때 머신러닝이 효과적이라는 것이다.

역으로 생각을 하자면 머신러닝이 규칙을 잘 찾기위해 유도를 한다면 성능의 상승으로 이어진다는 것이다.

그래서 성능이 안좋은데 어떻게 해요? 라는 질문에 입력 데이터가 한쪽으로 쏠리는 경향이 있으면 안된다, feature를 잘 뽑아야 한다 라는 답변을 받는 것이다.



 <h2><b>머신러닝으로 퉁치나요?</b></h2>

머신러닝은 하나의 큰 분류이다. 그 안에서 방식에 따라 구조에 따라 또 다시 분류되어 있다. 딥러닝은 머신러닝이지만 모든 머신러닝이 딥러닝은 아닌것처럼.

머신러닝은 크게 다음과 같이 나눈다고 한다.

- 직접적으로 정답을 알려줄 것인가? (지도, 비지도, 준지도, 강화 학습)
- 실시간으로 학습이 이루어 지는가? (온라인, 배치)
- 현재 가진 데이터와 새로운 데이터의 포인트를 비교하는 것인가 훈련 데이터셋에서 패턴을 발견해 예측을 하는가 (사례 기반, 모델 기반 학습)



 <h2><b>지도 학습? 비지도 학습?</b></h2>

학습하는 동안의 감독 형태나 정보량에 따른 분류이다.



<h3><b>1. 지도 학습</b></h3>

우리가 책으로 접하는 예제의 대부분이 지도 학습이다. MNIST가 이러하고 집값 예측이 이러하다.

지도 학습은 학습 시에 내가 원하는 정답을 주었는가 아닌가이다.

다음은 지도 학습 알고리즘의 종류이다.

- k-최근접 이웃 (K-nearest neighbors)
- 선형 회귀 (Linear regression)
- 로지스틱 회귀 (Logistic regression)
- 서포트 백터 머신 (Support Vector Machin, SVM)
- 결정 트리 (Decision tree)
- 랜덤 포레스트 (Random forest)
- 신경망 (Neural networks)



<h3><b>2. 비지도 학습</b></h3>

비지도 학습은 지도 학습과 반대로 정답을 주지 않은 경우이다.

시스템이 아무런 도움 없이 학습을 해야 한다.

다음은 비지도 학습 알고리즘의 종류이다.

- 군집 (Clustering)
  - k-평균 (K-means)
  - 밀도 기반 클러스터링 (Density-Based Spatial Clustering of Applications with Noise, DBSCAN)
  - 계층 군집 분석 (Hierarchical Cluster Analysis, HCA)
  - 이상치 탐지 (Outlier detection)
  - 특이치 탐지 (Novelty detection)
  - 원 - 클래스 (One-class)
  - 아이솔레이션 포레스트 (Isolation forest)
- 시각화 (Visualization)와 차원 축소 (Dimensionality reduction)
  - 주성분 분석 (Principal component analysis, PCA)
  - 커널 (Kernel)
  - 지역적 선형 임베팅 (Locally - Linear Embedding, LLE)
  - t - SNE (t-distributed Stocahstic Neighbor Ebedding)
- 연관 규칙 학습 (Association rule learning)
  - 어프라이어리 (Apriori)
  - 이클렛 (Eclat)



<h3><b>3. 준지도 학습</b></h3>

일부만 정답이 있는 데이터를 다루는 경우 이를 준지도 학습이라고 한다.

대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조합으로 이루어져 있다.

알고리즘 역시 섞여있다고 생각하면 된다.



<h3><b>4. 강화 학습</b></h3>

강화 학습(Reinforcement learning)은 매우 다른 종류의 알고리즘이다.

여기에서는 학습 시스템을 에이전트라고 부르며 환경을 관찰해 행동을 실행하고 그 결과로 보상 또는 벌을 받는다.

가장 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 스스로 학습한다.

알파고가 특히 대표적이다.

또 인터넷에서 쉽게 구할 수 있는 예제중 슈퍼마리오가 있다. 슈퍼마리오와 같은 게임은 보상과 벌을 측정하기 비교적 쉬운편이기 때문에 처음 접하는 예제로 많이 쓰는 것 같다. 물론 게임과 코드를 연동하는 것은 어렵다.



<h2><b>배치 학습? 온라인 학습?</b></h2>

이 두가지는 입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지에 대한 여부다.



<h3><b>1. 배치 학습</b></h3>

시스템이 점진적으로 학습할 수 없는 환경이다. 오프라인 학습이라고도 한다.

일반적으로 시간과 자원을 많이 소모하기 때문에 오프라인에서 수행을 하게 된다.

즉, 학습한 것만을 이용하는 방식이다.

데이터를 업데이트하고 시스템의 새 버전을 필요한 만큼 자주 훈련시키면 되지만 전체 데이터 셋을 사용해 훈련하는 데 몇 시간 길게는 몇주가 걸린다.



<h3><b>2. 온라인 학습</b></h3>

데이터를 순차적으로 한 개씩 또는 미니배치단위로 시스템을 훈련시킨다.

매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습한다.

온라인 학습 시스템에서 중요한 것은 변화하는 데이터에 얼마나 빠르게 적응할 것인가이다. 이를 학습률 (learning rate)라고 한다.

미니배치, 컴퓨팅 자원이 제한된 경우 라는 키워드를 보면 여태 내가 했던 방식은 온라인 학습이었던 것 같다.



<h2><b>사례 기반? 모델 기반?</b></h2>

어떻게 일반화(Generalizae) 되는가에 따라 분류한다.

머신러닝은 훈련 데이터를 통해 일반화를 하고 훈련 데이터에서는 본 적 없는 새로운 데이터에서 높은 퍼포먼스를 보여줘야 한다.

이 일반화를 위한 두 가지 접근법이다.



<h3><b>1. 사례 기반 학습</b></h3>

사례 기반 학습의 키워드는 단순한 기억이다.

시스템이 훈련 샘플을 기억함으로써 유사도 측정을 통해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화 한다.

저장된 훈련 데이터에서 가장 가까운 것을 찾는다고 생각하면 편할 것 같다.



<h3><b>2. 모델 기반 학습</b></h3>

이 샘플들의 모델을 만들어 예측에 사용하는 것이다.

대부분의 머신 러닝 모델이 이에 해당한다.

딥러닝에 관심이 생겨 산 책에 예제나 글을 보면 가중치가 있습니다, 비용함수가 있습니다, 오차역전파를 합니다, 모델 파라미터를 조정 합니다 등등이 써있다. 이러한 것들이 모델 기반 학습의 특징이다.



<h2><b>머신러닝의 주요 도전 과제</b></h2>

머신러닝의 주요 작업은 학습 알고리즘을 선택해서 어떠한 데이터에 대해 훈련시키고 새로운 데이터에 반응 하는 것이다. 다음과 같은 것들이 중요하다.

- 훈련 데이터의 양은 충분히 많아야한다.

- 훈련 데이터는 일반화 사례를 잘 나타내야 한다. 즉, 대표성이 있어야한다.
  다음을 조심하자

  - 샘플이 작을 때 Sampling Noise가 생길 수도 있다.
  - 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못할 수 있다. Sampling bias라고 한다.

- 에러, 이상치(outlier), 잡음과 같이 저품질의 데이터를 피해야 한다.

- 관련 있는 feature로 데이터를 구성해야한다. feature engineering에서는 다음과 같은 일을 한다.

  - feature selection : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택한다.
  - feature extraction : 특성을 결합해 더 유용한 특성을 만든다.

  

<h2><b>과대 적합(Overfitting), 과소 적합(Underfitting)</b></h2>

<h3><b>1. Overfitting</b></h3>

학습한 데이터에 대해 너무 잘 맞게된 경우이다. 즉 일반화가 되어 있지 않다.

오버피팅은 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 일어난다.

해결방법은 다음과 같다.

- 파라미터 수가 적은 모델을 선택한다.
- 훈련 데이터에 있는 특성 수를 줄인다.
- 모델에 제약을 가해 단순화 시킨다.(Regularization)
- 훈련 데이터를 더 많이 제공한다.
- 훈련 데이터의 잡음을 줄인다.(오류 데이터 혹은 이상치 등)



<h3><b>2. Underfitting</b></h3>

오버피팅의 반대이다. 모델이 너무 단순해서 데이터의 구조를 학습하지 못할 때 일어난다.

훈련 샘플에서조차도 부정확한 예측을 만든다는 것이다. 해결방안은 다음과 같다.

- 모델 파라미터가 더 많은 강력한 모델을 선택한다.
- 학습 알고리즘에 더 좋은 특성을 제공한다.
- 모델의 제약을 줄인다.



<h2><b>테스트와 검증</b></h2>

우리는 계속해서 머신러닝의 목적은 적절한 일반화라고 했다. 이를 서비스로써 제공을 하려면 우리는 모델이 일반화가 적절히 되어있다는 확신을 가지고 해야 한다. 

이 확신은 어떻게 가질까? 학습한 데이터로 확인을 해야할까? 당연히 아니다.

일반적인 방법은 가진 데이터의 80% 만을 학습에 사용하고 20%를 평가용으로 사용한다.

학습용 데이터를 train set, 평가용 데이터를 test set이라고 부른다.

평가용 데이터에서 높은 정확도를 보였지만 실제 서비스에서는 낮은 성능을 낼 수 있다.

모델과 하이퍼파라미터가 테스트 세트에 최적화되었기 때문이다. 

이 문제를 해결하는 일반적인 방법은 홀드아웃 검증 (holdout validation)이다.

훈련 세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택한다.

떼어낸 데이터 세트를 검증 세트 (Validation set) / 개발 세트 (Development set) / 데브 세트 (Dev set) 등으로 부른다.

검증 세트가 너무 작거나 큰 경우 문제가 될 수 있다. 이 문제를 해결하기 위해 작은 검증 세트를 여러 개를 사용해 반복적인 교차 검증(cross-validation)을 수행하는 것이다.

훈련 데이터(일부는 검증용) + 테스트 데이터로 수행하고

훈련 데이터(또다른 일부를 검증용으로) + 데스트 데이터

이러한 식으로 하기 때문에 검증 세트의 개수에 비례해 시간이 늘어나는 단점이 있다.

훈련-개발 세트는 검증,테스트 세트에 사용되는 데이터와 훈련 세트 사이에 데이터 불일치 위험이 있을 때 사용한다. 이것 역시 훈련 데이터에서 일부를 떼어내는 방식이다.

훈련 세트에서는 잘 동작하고 훈련-개발 세트에서 나쁜 성능을 낸다면 오버피팅이 일어났을 가능성이 크다.

훈련 세트와 훈련-개발 세트에서 좋은 성능을 내고 개발 세트에서 성능이 나쁘다면 훈련 데이터와 검증+테스트 데이터 사이에 데이터 불일치가 있을 가능성이 높다.